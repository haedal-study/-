# 메모리

# RAM과 ROM

컴퓨터에서 사용하는 저장장치는 CPU에 직접 접근할 수 있는지 여부에 따라 **주기억장치**(primary storage, main memory )와 **보조기억장치**(auxiliary storage, secondary storage)로 구분할 수 있다. 주기억장치는 다시 **RAM**(Random Access Memory)와 **ROM**(Read Only Memory)로 나눌 수 있다.

## ROM

우선 ROM에 대해 살펴보자. ROM은 비휘발성이며 Read Only라는 이름 그대로 한번 기록한 이후 수정이 불가능했다. (기록하기 위해 사용한 장치를 ROM Writer 라고 한다.) 따라서 수정할 필요가 없는 펌웨어나 컴퓨터 바이오스에서 사용하였다.

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/457467bb-85d6-4229-b267-0f3b32787daf" width="75%" height="75%">

([ROM](https://en.wikipedia.org/wiki/Read-only_memory))

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/48ccc944-e0b6-4ac3-ae65-e80d900c4cac" width="75%" height="75%">

([ROM Writer](https://www.n-denkei.com/korea/items/category5-15/))

과거형으로 이야기하는 이유는 기술이 발전함에 따라  EPROM, EEPROM와 같은 내용을 다시 기록할 수 있는 ROM이 등장하였고, 최근에는 기록 횟수에 제한이 있으나 빠른 속도, 적은 전력 소모, 고밀도의 용량의 장점을 가진 플래시 메모리(보조기억장치에 속한다.)가 등장하였기 때문이다. 현재는 플래시 메모리를 ROM 대신하여 스마트폰, 임베디드, USB, SSD에 활용하고 있다.

## RAM

RAM은 ROM과 달리 휘발성이지만, 임의 접근이 가능하여 빠른 응답시간을 보장한다. 따라서 주기억장치나 캐시 메모리로 많이 사용한다.

**RAM ROM 비교**

|  | RAM | ROM |
| --- | --- | --- |
| 휘발성 | O | X |
| 가격 | ↑ | ↓ |
| 속도 | ↑ | ↓ |
| 용도 | CPU Cache, Main Memory | Firmware, Embaded |
| 읽기 가능 여부 | O | O |
| 쓰기 가능 여부 | O | △ |

## RAM의 종류

ROM과 마찬가지로, RAM 역시 시간에 따라 발전하고 다양한 종류가 나오게 되었다. 이들에 대해서 살펴보자.

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/e0595f1f-a698-4928-b0ab-b4abcb9ff6b5" width="75%" height="75%">

([RAM](https://ko.ifixit.com/Device/RAM))

### DRAM

Dynamic RAM의 줄임말이다. 데이터가 시간이 지나면 사라진다는 특성이 있지만, 높은 집적도 & 저렴한 가격 & 낮은 소비 전력 등의 이유로 주기억장치에서 많이 사용한다.

### SRAM

Static RAM의 줄임말이다. DRAM과 달리 데이터가 시간이 지나도 사라지지 않으며, 속도도 비교적 빠르다. 하지만 높은 집적도 & 비싼 가격 & 높은 소비전력의 이유로 캐시 메모리에 주로 사용한다.

(Static 이라고 하여 비휘발성인 것은 아니다. 전원 공급은 필요하다.)

**DRAM vs SRAM**

|  | DRAM | SRAM |
| --- | --- | --- |
| 재충전 (데이터 사라짐 방지 목적) | O | X |
| 속도 | ↓ | ↑ |
| 가격 | ↓ | ↑ |
| 집적도 | ↑ | ↓ |
| 소비 전력 | ↓ | ↑ |
| 용도 | 주기억장치 | 캐시 메모리, 레지스터 |

### SDRAM

Synchronous Dynamic RAM의 줄임말로, 기존과 달리 동기식으로 명령을 처리할 수 있어 CPU가 메모리 응답을 기다리지 않게 되었다.

### DDR SDRAM

Double Data Rate SDRAM으로 최근에 흔히 사용하는 RAM이다. 기존 SDRAM과 비교했을 때, 대역폭이 증가하여 많은 양의 데이터를 주고받을 수 있다. 아래 그림과 같이 자동차가 지나갈 수 있는 길이 넓어져 많은 차가 지나갈 수 있는 것과 유사하다. DDRN SDRAM이라면 SDRAM에 비해 2<sup>N</sup>배 많은 대역폭을 가진다.

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/a6c8b54b-c32a-4a08-90aa-acb3e96f990a" width="75%" height="75%">

([DDR SDRAM의 대역폭 비유](https://www.youtube.com/watch?v=Lvf-Su8eEDc))

## 참고

- DRAM: https://semiconductor.samsung.com/kr/dram/
- ROM vs RAM: https://ungung1.tistory.com/167
- 플래시메모리: [https://ybkstorage.tistory.com/entry/반도체-플래시-메모리Flash-Memory](https://ybkstorage.tistory.com/entry/%EB%B0%98%EB%8F%84%EC%B2%B4-%ED%94%8C%EB%9E%98%EC%8B%9C-%EB%A9%94%EB%AA%A8%EB%A6%ACFlash-Memory)

---

# 메모리의 주소 공간

데이터들은 메모리의 **주소**라는 체계속에 저장된다. 주소는 **물리 주소**와 **논리 주소**로 나눌 수 있는데, 이 두 가지의 종류에 대해 알아보자.

## 주소 바인딩

두 가지 종류에 대해 알아보기 앞서, 주소 바인딩에 대해 알아보자.

**주소 바인딩**은 보조 기억장치에 있던 프로그램이 주기억장치에 로드될 때(프로세스가 될 때) 메모리의 주소를 매핑하는 작업이다.

주소 바인딩은 시점에 따라

- 컴파일 타임 바인딩
- 로드 타임 바인딩
- 런 타임 바인딩

으로 나눌 수 있다.

**컴파일 타임 바인딩**은 컴파일 시점에 사전에 정한 주소로 매핑한다. 메모리에 로드하는 동작 자체는 빠르게 이루어지나, 다른 프로세스의 점유 공간에 매핑되어 다시 컴파일을 하는 경우가 잦다.

**로드 타임 바인딩**은 로드 시점에 주소를 결정한다. 따라서 앞서 언급했던 충돌 발생을 피할 수 있다. (물론, 프로세스의 크기가 너무 크기가 커서 침범하는 경우는 있다.) 모든 주소를 재배치해야하기 때문에 로딩 시간이 오래 걸리는 문제가 있다.

이러한 문제들을 해결하는 방법이 런 타임 바인딩이다. **런 타임 바인딩**은 **논리 주소**만을 가지고 있다가 코드가 실행되는 시점에 **물리 주소**를 결정한다. 로드 타임 바인딩에 비해 작은 재배치가 오래 발생하여 빈번한 주소 변환 과정이 발생하는데, 이는 MMU(Memory Management Unit)라는 하드웨어가 대신 수행하여 해소한다. 

MS-DOS 같은 특수한 환경을 제외하고, Window, Linux 등 현대 운영체제 시스템에서는 대부분 런 타임 바인딩을 주로 사용한다.

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/cb755683-a6d1-47cb-b75a-49912a7d79e6" width="75%" height="75%">

([주소 바인딩](https://core.ewha.ac.kr/publicview/C0101020140502151452123728?vmode=f))

위 그림을 살펴보면,

- 컴파일 타임 바인딩은 논리주소와 물리주소가 같다.
- 로드 타임 바인딩은 논리주소와 물리주소가 다르지만, 주소가 변경되진 않는다.
- 런 타임 바인딩은 논리주소와 물리주소가 다르고, 실행 중에 변경된다.

## 논리주소의 원리

논리주소는 베이스 레지스터와 한계 레지스터를 가지고 있다. 프로세스가 N번지를 사용한다고 하면

> 물리주소: 베이스 레지스터 + N번지
> 

로 물리주소를 결정한다. 또한, 이렇게 정해진 물리 주소가 정해진 한계주소보다 크다면 인터럽트를 발생시켜 실행을 중단한다.

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/319be155-4c65-4951-888b-61ce685c6e68" width="75%" height="75%">

([논리주소 동작](https://www.youtube.com/watch?v=_mQNCRA1fVA))

## 논리주소 사용의 이점

논리주소를 사용하지 않는다면, 주소가 변할 때마다 변하는 주소를 CPU가 기억하고 있어야 한다. CPU가 이를 모두 기억하기에는 비용도 많이 들고, 용량도 충분치 않다. 따라서 CPU는 모든 주소가 0번지부터 시작한다고 가정한 후 논리주소로 변환 작업만 거치면 비용과 용량 문제를 해결할 수 있다.

# 캐시 메모리

## 캐시 메모리의 등장 배경

캐시 메모리가 어떤 과정을 거쳐 등장하게 되었는지를 살펴보겠습니다. 

### 병목현상의 발생

초기에 에니악 등을 이용하여 연산을 하던 시절에는, 컴퓨터는 연산을 변경하기 위해선 모든 전선, 회로들을 바꿔야 하는 **Fixed Program Computers** 방식을 사용했습니다. 일일이 회로를 수정해야 하는 문제점은 이후 프로그램을 데이터와 마찬가지로 내부 장치에 저장하는 **Stored Program Computer** 방식인  폰 노이만 구조가 도입되어 해결이 되었습니다.

하지만, 폰 노이만 구조는 다음과 같은 문제점이 있습니다.

1. 메모리에서 값을 가져와 연산을 한 후 다시 메모리로 써야 한다.

   → 연산이 아무리 빠르더라도, 메모리 작업이 느리다면 작업이 늦게 끝난다. (병목 현상 발생)

   <img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/441b8748-f1e7-412a-8320-2f5d26989229" width="75%" height="75%">

   (시간이 지남에 따라 벌어지는 CPU와 주기억장치의 성능차이)

2. 명령어와 데이터가 같은 곳에 저장되어 있고, 시스템 버스를 이용하여 가져온다

   → 메모리를 가져오기 전 까지 명령어를 가져오지 못한다. (병목 현상 발생)


### 병목현상의 해소방안

(2)의 문제점은 하버드 구조에서  명령어와 데이터를 다른 곳으로 저장하고 시스템 버스 역시 두 개로 나누어 어느정도 해소 하였으며,

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/525dc18e-a15a-4a19-b7f6-986e48d3652b" width="75%" height="75%">

(데이터, 프로그램이 다른 곳에 저장되고 다른 버스를 사용하는 하버드 구조)

(1)의 문제점은 **메모리 계층 구조**를 도입하여 빠른 메모리 접근을 가능하게 하여 해소하였습니다.

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/855dd8eb-c8c1-4038-a136-5b6e5cbd6efc" width="75%" height="75%">

(메모리 계층구조)

### 메모리 계층구조

메모리 계층구조는 위와 같이 CPU에 가까울수록 속도 ↑, 가격 ↑ 용량 ↓인 장치를, 멀어질수록 속도 ↓, 가격 ↓ 용량 ↑인 장치를 계층적으로 배치하여 사용하는 구조를 의미합니다. 

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/677e756a-faf1-4c80-b061-a4b818a7589d" width="75%" height="75%">

(주기억장치 대신 캐시 메모리에 접근하는 모습을 대형마트, 편의점으로 비유)

메모리 계층구조를 도입하였을 때 병목현상을 줄일 수 있는 까닭은 다음과 같습니다. 위 그림 처럼 CPU는 우선 가까운 저장장치에 들러 데이터를 가져오고, 이를 찾지 못했을 때 먼 저장장치를 들르게 됩니다. 가까운 장치는 속도가 상대적으로 빠르고 이러한 장치에 들렀을 때,  빠른 접근 속도를 누릴 수 있어 병목현상을 해소할 수 있습니다. 다시말해, **캐시 메모리**는 레지스터-메모리 사이의 병목현상을 줄이기 위해 사용합니다. 

## 캐시 메모리의 특징

캐시 메모리는 SRAM을 활용합니다. SRAM은 CMOS 기술과 트랜지스터로 만들어져 적은 전력 소모와 빠른 속도를 자랑합니다. 하지만 비싼 가격으로 인해 주기억장치가 아닌 캐시 메모리, 레지스터에 활용되고 있습니다.

### 참조 지역성 원리

캐시 메모리는 주기억장치의 내용 중 일부를 복사하여 저장하고, CPU는 주기억장치이전에 캐시 메모리에 들러 찾고자하는 데이터가 있는지 여부를 확인합니다. 캐시 메모리에 해당 데이터가 있어 활용되는 경우를 **캐시 히트**, 데이터를 찾지 못해 주기억장치에서 데이터를 가져오는 경우를 **캐시 미스** 라고 합니다. 당연하게도 캐시 히트가 많을 수록, 캐시 미스가 적을 수록 성능은 뛰어나며 이 두 가지 상황의 빈도를 통해 성능을 계산하는 지표 중 하나인 **캐시 적중률**은 다음과 같이 계산할 수 있습니다.

> 캐시 적중률 = 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)
> 

일반적으로 CPU는 85 ~ 95%의 적중률을 가지고 있다고 합니다. 어떻게 해서 이렇게 높은 적중률을 가지게 되었을 까요? 이는 **참조 지역성의 원리**를 ****활용했기 때문입니다.

참조 지역성의 원리는 메모리에서 데이터를 가져오는 경험을 토대로 만들어진 원리로, 최근에 접근한 공간을 다시 접근하려는 경향성인 시간적 지역성(Temporal localicy)와 근처 공간을 접근하려는 경향성인 공간적 지역성(Spatial localicy)로 구분할 수 있습니다.

```cpp
for(int i=0;i<10;++i) {
  sum += arr[i]
}
```

위와 같은 코드가 있다면, sum이라는 데이터는 지속적으로 재접근하므로 시간적 지역성을 활용할 수 있을 것이고, arr[i]는 배열이라는 주변 공간을 재접근하므로 공간적 지역성을 활용할 수 있을 것 입니다.

실제로 프로세스가 접근하는 시점과 그 때의 접근하려는 메모리 주소를 표현한 그림은 아래와 같습니다.

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/b2b597c8-6f97-4dcd-bca0-32d62cd8384b" width="75%" height="75%">

([프로세스 접근 이미지](https://parksb.github.io/article/29.html))

시간적 지역성과 공간적 지역성이 실제로 활용되는 것을 알 수 있습니다.

## 캐시 메모리 접근 방법

캐시는 해시 테이블 자료구조와 유사하게 key를 통해 공간에 접근할 수 있습니다. 참고로 캐시의 공간은 블록단위(32Byte)로 구성되어 있습니다.

CPU에서 접근하려는 메모리 주소가 캐시에 저장되어 있는지 확인하기 위해선 아래와 같은 동작이 이루어집니다. 블록 개수가 1024개이고 32비트 주소라고 가정하면,

- [0, 4): block offset
- [4, 14): index bit
- [14, 31]: tag bit

로 활용됩니다. 이후 아래의 과정을 통해 케시 메모리에서 데이터를 처리합니다.

1. 인덱스 비트를 통해 태그 배열의 필드를 조회
2. 태그 배열의 필드값이 태그 비트와 같고, 태그 배열의 유효비트가 참인지 확인
3. 유효비트가 참이고 태그비트와도 같다면 **캐시 히트** → 블록 오프셋을 활용하여(블록 단위 → 바이트 단위로 접근하게 함) 데이터 접근
4. 유효비트가 거짓이라면 **캐시 미스** → 주기억장치에서 조회 후 캐시 메모리에 저장
5. 유효비트가 참인데, 태그비트는 같다면 교체 정책(FIFO, LRU 등)에 따라 어떤 데이터를 저장할지 결정

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/2f4f6415-cd5c-40af-89a4-4cac7e13cfe7" width="75%" height="75%">

([태그 매칭](https://parksb.github.io/article/29.html) )

서로 다른 주소의 인덱스가 같고 두 주소 모두 자주 접근해야한다면 캐시 메모리의 해당 인덱스는 빈번하게 데이터 교체가 발생할 것이다. 태그 배열과 데이터 배열을 여러 개를 만들고, 병렬적으로 여러 배열을 조회하면 이러한 문제를 해결할 수 있다.

<img src="https://github.com/Invidam/self-learning-comp-archi/assets/71889359/e0556615-aa9c-4ab3-8386-8fd36fab8313" width="75%" height="75%">

([캐시 병렬](https://parksb.github.io/article/29.html) )

### 캐시 쓰기 정책

캐시 메모리는 읽기 작업 뿐만 아니라 쓰기 작업을 진행하는 경우도 있다. 쓰기 작업의 주소가 캐시 메모리에 저장되어있다면, 캐시 메모리의 데이터에 쓰여진다. 캐시 메모리에 쓰여진 데이터는 언젠간 주기억장치에 동기화가 이루어져야 하는데 이를 위한정책은 2가지가 있다.

- Write-through: 캐시에 데이터가 쓰여질 때마다 주기억장치와 동기화한다.
  - 장점: 캐시 메모리와 주기억장치를 항상 같게 유지할 수 있음.
  - 단점: 매번 주기억장치에 쓰기 작업을 해야 해 비용이 많이 든다.
- Write-back: 블록에 수정이 있을 때 dirty bit를 1로 변경해준다.
  - 이는 추후 블록이 교체될 때 주기억장치에 반영된다.
  - 장점: 접근 시간이 큰 주기억장치에 데이터를 저장하는 빈도가 줄어 비용이 적게 든다.
  - 단점: 별도 공간에 dirty 비트를 관리해주어야 한다.

## 캐싱의 활용

현재 캐싱은 캐시 메모리 뿐만이 아닌 다양한 영역에서 사용한다.

- 네트워크
  - CDN: 분산 서버가 캐싱된 데이터를 응답해주는 서비스
  - DNS: IP주소에 대응하는 도메인 네임을 찾는 서비스 (거쳐가는 여러 장치에서 캐싱된 도메인 네임을 응답)
- 웹과 API
  - 웹 캐시: 정적 컨텐츠들을 브라우저에서 캐싱 후 응답 (프록시, 게이트웨이에서 캐싱하기도 함.)
  - API: API 자체를 캐싱하기도 한다.
- 데이터베이스
  - 쿼리 캐시: DB에 요청한 응답을 캐시하여 줌.
  - Redis: 보조기억장치의 DB 대신 주기억장치에 데이터를 보관하는 DB (데이터를 캐싱하여 주기도 함)

등등에서 활용된다.

## 참고

- 주소바인딩: https://gamedevlog.tistory.com/83
- 논리주소가 등장한 이유: [https://www.inflearn.com/questions/859946/메모리에서-물리주소와-논리주소를-나눈-이유](https://www.inflearn.com/questions/859946/%EB%A9%94%EB%AA%A8%EB%A6%AC%EC%97%90%EC%84%9C-%EB%AC%BC%EB%A6%AC%EC%A3%BC%EC%86%8C%EC%99%80-%EB%85%BC%EB%A6%AC%EC%A3%BC%EC%86%8C%EB%A5%BC-%EB%82%98%EB%88%88-%EC%9D%B4%EC%9C%A0)
- 로드타임바인딩의 오버헤드: https://jhnyang.tistory.com/246
- 주소 바인딩과 운영체제: https://www.baeldung.com/cs/address-binding-in-operating-systems
  
- 캐시 메모리 등장 배경
  - https://wkddntjr1123.github.io/cs/cache/
  - https://biz.chosun.com/site/data/html_dir/2016/11/23/2016112300511.html
- 캐시: https://bluayer.com/55
- 캐싱 동작 원리: https://parksb.github.io/article/29.html
- 캐싱 다양한 활용: https://aws.amazon.com/ko/caching/
